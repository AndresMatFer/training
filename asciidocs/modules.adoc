= Modularization

The definition of module libraries simplifies the writing of complex data analysis pipelines and makes re-use of processes much easier.

Using the `hello.nf` example from earlier, we will convert the pipeline's processes into modules, then call them within the workflow scope in a variety of ways and explore the ways we can modularise Nextflow workflows. 

== Modules

Nextflow DSL2 allows for the definition of stand-alone module scripts that can be included and shared across multiple workflows. Each module can contain its own `process` or `workflow` definition.

=== Importing modules

Components defined in the module script can be imported into other Nextflow scripts using the `include` statement. This allows you to store these components in a separate file(s) so that they can be re-used in multiple workflows.

Using the `hello.nf` example, we can achieve this by:

- Creating a file called `modules.nf` in the top-level folder containing the main Nextflow script.
- Cutting and pasting the two process definitions for `splitLetters` and `convertToUpper` into `modules.nf`.
- Importing the processes from `modules.nf` within the main script anywhere above the `workflow` definition:

[source,nextflow,linenums]
----
include { SPLITLETTERS   } from './modules.nf'
include { CONVERTTOUPPER } from './modules.nf'
----

NOTE: In general, you would use relative paths to define the location of the module scripts using the `./` prefix.

[discrete]
=== Exercise

Create a `modules.nf` file with the previously defined processes from `hello.nf`. Then remove these processes from `hello.nf` and add the `include` definitions shown above.

.Click here for the answer:
[%collapsible]
====
The `hello.nf` script should look like this:
[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting  = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

include { SPLITLETTERS   } from './modules.nf'
include { CONVERTTOUPPER } from './modules.nf'

workflow {
    letters_ch = SPLITLETTERS(greeting_ch)
    results_ch = CONVERTTOUPPER(letters_ch.flatten())
    results_ch.view{ it }
}
----

You should have the following in the file `.modules.nf`:
[source,nextflow,linenums]
----
process SPLITLETTERS {
    input:
    val x

    output:
    file 'chunk_*'

    """
    printf '$x' | split -b 6 - chunk_
    """
}

process CONVERTTOUPPER {
    input:
    file y

    output:
    stdout

    """
    cat $y | tr '[a-z]' '[A-Z]' 
    """
}
----
====

== Output definition

In the example above, we define the channel names to specify the input to the next process. We can also explicitly define the output of one process to another using the `.out` attribute. In this way, we can manipulate the output of a process, as shown below:

[source,nextflow,linenums]
----
    letters_ch = SPLITLETTERS(greeting_ch)
    results_ch = CONVERTTOUPPER(letters_ch.out.flatten())
----

=== Specifying outputs

If a process defines two or more output channels, each channel can be accessed by indexing the `.out` attribute, e.g., `.out[0]`, `.out[1]`, etc.

Additionally, the process `output` definition allows the use of the `emit` statement to define a named identifier that can be used to reference the channel in the external scope. 

For example, check the `emit` statement on the `convertToUpper` process in the following snippet:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

process SPLITLETTERS {
    input:
    val x

    output:
    file 'chunk_*'

    """
    printf '$x' | split -b 6 - chunk_
    """
}

process CONVERTTOUPPER {
    input:
    file y

    output:
    stdout emit: upper

    """
    cat $y | tr '[a-z]' '[A-Z]'
    """
}

workflow {
    letters_ch = SPLITLETTERS(greeting_ch)
    results_ch = CONVERTTOUPPER(letters_ch.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}
----

WARNING: In the above example, we have reverted to keeping the `process` definitions within the `hello.nf` script. However, this would work the same way if the emit defintion was in a `modules.nf` file.

=== Using piped outputs

Another way to deal with outputs in the workflow scope is to use pipes `|`. 

[discrete]
=== Exercise

Try changing the workflow script to the snippet below:

[source,nextflow,linenums]
----
workflow {
    Channel.from(params.greeting) | SPLITLETTERS | flatten() | CONVERTTOUPPER | view
}
----

=== Multiple imports

If a Nextflow module script contains multiple `process` definitions they can also be imported using a single `include` statement as shown in the example below:

[source,nextflow,linenums]
----
include { splitLetters; convertToUpper } from './modules.nf'
----

=== Module aliases

When including a module component it is possible to specify a name alias using the `as` declaration. This allows the inclusion and the invocation of the same component multiple times using different names. For example:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting = 'Hello world!'

include { SPLITLETTERS as SPLITLETTERS_one } from './modules.nf'
include { SPLITLETTERS as SPLITLETTERS_two } from './modules.nf'

include { CONVERTTOUPPER as CONVERTTOUPPER_one } from './modules.nf'
include { CONVERTTOUPPER as CONVERTTOUPPER_two } from './modules.nf'

workflow my_pipeline_one {
    take:
    greeting

    main:
    SPLITLETTERS_one(greeting)
    CONVERTTOUPPER_one(SPLITLETTERS_one.out.flatten())

    emit:
    my_data = CONVERTTOUPPER_one.out.upper
}

workflow my_pipeline_two {
    take:
    greeting

    main:
    SPLITLETTERS_two(greeting)
    CONVERTTOUPPER_two(SPLITLETTERS_two.out.flatten())

    emit:
    my_data = CONVERTTOUPPER_two.out.upper
}

workflow {
    my_pipeline_one(Channel.from(params.greeting))
    my_pipeline_one.out.my_data.view()

    my_pipeline_two(Channel.from(params.greeting))
    my_pipeline_two.out.my_data.view()
}
----

=== Parameter scopes

A module script can define one or more parameters or custom functions using the same syntax as with any other Nextflow script. Using the minimal examples below: 

[discrete]
==== Module script (`./modules.nf`)

[source,nextflow,linenums]
----
params.foo = 'Hello'
params.bar = 'world!'

def sayHello() {
    println "$params.foo $params.bar"
}
----

[discrete]
==== Main script (`./main.nf`)

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.foo = 'Hola'
params.bar = 'mundo!'

include { sayHello } from './modules.hello.nf'

workflow {
    sayHello()
}
----

Running `main.nf` should print:

[source,bash,linenums]
----
Hola mundo!
----

As highlighted above, the script will print `Hola mundo!` instead of `Hello world!` because parameters are inherited from the including context.

TIP: To avoid being ignored, pipeline parameters should be defined at the beginning of the script before any `include` declarations.

The `addParams` option can be used to extend the module parameters without affecting the external scope. For example:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.foo = 'Hola'
params.bar = 'mundo!'

include { sayHello } from './modules.nf' addParams(foo: 'Ciao')

workflow {
    sayHello()
}
----

Executing the main script above should print:

[source,bash,linenums]
----
Ciao mundo!
----

=== Workflow definition

The `workflow` scope allows the definition of components that define the invocation of one or more processes or operators:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting = 'Hello world!'

include { SPLITLETTERS } from './modules.nf'
include { CONVERTTOUPPER } from './modules.nf'


workflow my_pipeline {
    SPLITLETTERS(params.greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}

workflow {
    my_pipeline()
}
----

For example, the snippet above defines a `workflow` named `my_pipeline`, that can be invoked via another `workflow` definition.

=== Workflow parameters

A workflow component can access any variable or parameter defined in the outer scope. In the running example, we can also access `params.greeting` directly within the `workflow` definition.

[source,nextflow,linenums]
----
workflow my_pipeline {
    SPLITLETTERS(Channel.from(params.greeting))
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}

workflow {
    my_pipeline()
}
----

=== Workflow inputs

A `workflow` component can declare one or more input channels using the `take` statement. For example:

[source,nextflow,linenums]
----
workflow my_pipeline {
    take:
    greeting

    main:
    SPLITLETTERS(greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}
----

IMPORTANT: When the `take` statement is used, the `workflow` definition needs to be declared within the `main` block.

The input for the `workflow` can then be specified as an argument:

[source,nextflow,linenums]
----
workflow {
    my_pipeline(Channel.from(params.greeting))
}
----

=== Workflow outputs

A `workflow` can declare one or more output channels using the `emit` statement. For example:

[source,nextflow,linenums]
----
workflow my_pipeline {
    take:
    greeting

    main:
    SPLITLETTERS(greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())

    emit:
    CONVERTTOUPPER.out.upper
}

workflow {
    my_pipeline(Channel.from(params.greeting))
    my_pipeline.out.view()
}
----

As a result, we can use the `my_pipeline.out` notation to access the outputs of `my_pipeline` in the invoking `workflow`.

We can also declare named outputs within the `emit` block.

[source,nextflow,linenums]
----
workflow my_pipeline {
    take:
    greeting

    main:
    SPLITLETTERS(greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())

    emit:
    my_data = CONVERTTOUPPER.out.upper
}

workflow {
    my_pipeline(Channel.from(params.greeting))
    my_pipeline.out.my_data.view()
}
----

The result of the above snippet can then be accessed using `my_pipeline.out.my_data`.

== DSL2 migration notes

To view a summary of the changes introduced when Nextflow migrated from DSL1 to DSL2 please refer to the https://www.nextflow.io/docs/latest/dsl2.html#dsl2-migration-notes[DSL2 migration notes] in the official Nextflow documentation.

