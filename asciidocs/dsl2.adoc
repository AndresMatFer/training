= DSL2 and modules

== Basic concepts

DSL2 is a syntax extension to DSL1, developed primarily to allow the definition of module libraries and simplifies the writing of complex data analysis pipelines.

To ensure backward compatibility, you can use DSL2 by adding the following line at the beginning of each workflow script: 

----
nextflow.enable.dsl=2
----

DSL2 core features include:

* Separation of processes from their invocation.
* Use of a `workflow` directive to execute specific processes.
* Archiving of processes into modules.
* Update of syntax (pipe operator, & operator and channel forking)


To demonstrate the differences to DSL1, we will convert out first script `hello.nf` from earlier into DSL2.

== Process

=== Process definition

The new DSL separates the definition of a process from its invocation. The process definition follows the usual syntax as described in the process https://www.seqera.io/training/#_processes[documentation]. The only difference is that the `from` and `into` channel declaration has to be omitted.

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

nextflow.enable.dsl=2

params.greeting  = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

process splitLetters {

    input:
    val x

    output:
    file 'chunk_*'

    """
    printf '$x' | split -b 6 - chunk_
    """
}
----

IMPORTANT: Notice we have added `nextflow.enable.dsl=2`. Try without this line, to see the error this would cause. 

By removing the preset channels `from` and `into`, we allow the process to accept any value channel without needing to specify its channel name.

=== Workflow scope

To run this process in DSL2, we must be invoke it as a function in a `workflow` scope, passing the expected input channels as parameters as it if were a custom function. For example :

[source,nextflow,linenums]
----
workflow {
  splitLetters(greeting_ch)
}
----

IMPORTANT: A process component can be invoked only once in the same workflow context.

Next, we can add additional processes to this script and add another call from the workflow directive, thereby separating the processes into 'submodules'. 

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

nextflow.enable.dsl=2

params.greeting  = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

process splitLetters {

    input:
    val x

    output:
    file 'chunk_*'

    """
    printf '$x' | split -b 6 - chunk_
    """
}

process convertToUpper {

    input:
    file y

    output:
    stdout

    """
    cat $y | tr '[a-z]' '[A-Z]' 
    """
}

workflow {
  splitLetters(greeting_ch)
  convertToUpper(splitLetters.out.flatten())
  convertToUpper.out.view{ it }
}
----

In this workflow example, when we use the output of one process we use the appendage `.out`. In this way, we now have a simpler workflow scope to follow, that creates custom functions from processes defined earlier in the script.


If a process defines two or more output channels, each of them can be accessed using the array element operator e.g. `out[0]`, `out[1]`, etc. 

=== Process composition

Processes having matching input-output declaration can be composed so that the output of the first process is passed as input to the following process. Taking in consideration the previous process definition, it’s possible to write the following workflow directive:

[source,nextflow,linenums]
----
workflow {
  convertToUpper(splitLetters(greeting_ch).flatten())
  convertToUpper.out.view{ it }
}
----

Another option is using named outputs (see below).

=== Process named output

The process output definition allows the use of the `emit` option to define a name identifier that can be used to reference the channel in the external scope. For example:

[source,nextflow,linenums]
----
nextflow.enable.dsl=2

process convertToUpper {

    input:
    file y

    output:
    stdout emit: verbiage

    """
    cat $y | tr '[a-z]' '[A-Z]' 
    """
}

workflow {
  splitLetters(greeting_ch)
  convertToUpper(splitLetters.out.flatten())
  convertToUpper.out.verbiage.view{ it }
}
----

TIP: This works for output as a `value`, `path` or `stdout`


== Workflow

=== Workflow definition

The `workflow` keyword allows the definition of sub-workflow components that enclose the invocation of one or more processes and operators:

[source,nextflow,linenums]
----
workflow my_pipeline {
    foo()
    bar( foo.out.collect() )
}
----

For example, the above snippet defines a workflow component, named `my_pipeline`, that can be invoked from another workflow component definition as any other function or process i.e. `my_pipeline()`.

=== Workflow parameters

A workflow component can access any variable and parameter defined in the outer scope:

[source,nextflow,linenums]
----
params.data = '/some/data/file'

workflow my_pipeline {
    if( params.data )
        bar(params.data)
    else
        bar(foo())
}
----

=== Workflow inputs

A workflow component can declare one or more input channels using the `take` keyword. For example:

[source,nextflow,linenums]
----
workflow my_pipeline {
    take: data
    main:
    foo(data)
    bar(foo.out)
}
----

IMPORTANT: When the `take` keyword is used, the beginning of the workflow body needs to be identified with the `main` keyword.

Then, the input can be specified as an argument in the workflow invocation statement:

[source,nextflow,linenums]
----
workflow {
    my_pipeline( channel.from('/some/data') )
}
----

NOTE: Workflow inputs are by definition: channel data structures. If a basic data type is provided instead, i.e. number, string, list, etc., it’s implicitly converted to a channel value (ie. non-consumable).

=== Workflow outputs

A workflow component can declare one or more out channels using the emit keyword. For example:

[source,nextflow,linenums]
----
workflow my_pipeline {
    main:
      foo(data)
      bar(foo.out)
    emit:
      bar.out
}
----

Then, the result of the `my_pipeline` execution can be accessed using the out property i.e. `my_pipeline.out`. When there are multiple output channels declared, use the array bracket notation to access each output component as described for the Process outputs definition.

Alternatively, the output channel can be accessed using the identifier name it’s assigned to in the emit declaration:

[source,nextflow,linenums]
----
workflow my_pipeline {
   main:
     foo(data)
     bar(foo.out)
   emit:
     my_data = bar.out
}
----

Then, the result of the above snippet can accessed using `my_pipeline.out.my_data`.

== Modules

The new DSL allows the definition of module scripts that can be included and shared across workflow applications.

A module can contain the definition of a function, `process` and `workflow` definitions as described in the above sections.

=== Modules include

A component defined in a module script can be imported into another Nextflow script using the `include` keyword. This way, you can store all your processes in separate files that could be used by a variety of scripts.

Lets try to complete this for our example `hello.nf`.

For example, first create a file called `modules.nf` which contains the two processes `splitLetters` and `convertToUpper` in your current directory, or in a folder called `modules` (this is the standard location for nextflow modules)

Next, in your `hello.nf` script, remove the process defintions, and include the following lines above your workflow scope: 

[source,nextflow,linenums]
----
include { splitLetters } from './path/to/modules.nf'
include { convertToUpper } from './path/to/modules.nf'
----

The above snippets include a process with name `splitLetters` and `convertToUpper` defined in the module script in the main execution context, as such it can be invoked in the `workflow` scope. "modules.nf" can contain multiple process code blocks, or you can separate each process into a single module file. 

Nextflow implicitly looks for the script file "./path/to/modules.nf", resolving the path within the included script location.

NOTE: Relative paths must begin with the `./` prefix.

=== Multiple inclusions

A Nextflow script allows the inclusion of any number of modules. When multiple components need to be included from the same module script, the component names can be specified in the same inclusion using the curly brackets notation as shown below:

[source,nextflow,linenums]
----
include { splitLetters; convertToUpper } from './path/to/modules.nf'

workflow {
  splitLetters(greeting_ch)
  convertToUpper(splitLetters.out.flatten())
  convertToUpper.out.verbiage.view{ it }
}
----

=== Module aliases

When including a module component it’s possible to specify a name alias. This allows the inclusion and the invocation of the same component multiple times in your script using different names. For example:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

nextflow.enable.dsl=2

params.greeting  = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

params.greeting2  = 'Hola! Mundo!'
greeting_ch2 = Channel.from(params.greeting2)

include { splitLetters } from './path/to/modules.nf'
include { splitLetters_repeat as splitLetters } from './other/module'

include { convertToUpper } from './path/to/modules.nf'
include { convertToUpper_repeat as convertToUpper } from './other/module'

workflow {
  splitLetters(greeting_ch)
  convertToUpper(splitLetters.out.flatten())
  convertToUpper.out.verbiage.view{ it }

  splitLetters_repeat(greeting_ch2)
  convertToUpper(splitLetters.out.flatten())
  convertToUpper.out.verbiage.view{ it }
}
----

The same is possible when including multiple components from the same module script as shown below:

[source,nextflow,linenums]
----
include { splitLetters; splitLetters as splitLetters_repeat } from './path/to/modules.nf'
----

=== Module parameters

A module script can define one or more parameters using the same syntax as Nextflow workflow scripts (as well as defining workflow or defined functions):

[source,nextflow,linenums]
----
params.foo = 'Hello'
params.bar = 'world!'

def sayHello() {
    println "$params.foo $params.bar"
}
----

Parameters are inherited from the including context. For example:

[source,nextflow,linenums]
----
params.foo = 'Hola'
params.bar = 'Mundo'

include {sayHello} from './some/module'

workflow {
    sayHello()
}
----

The above snippet should print:

[source,bash,linenums]
----
Hola Mundo
----

NOTE: The module inherits the parameters defined before the include statement, therefore any further parameters set later are ignored.

TIP: Define all pipeline parameters at the beginning of the script before any include declaration.

The option `addParams` can be used to extend the module parameters without affecting the external scope. For example:

[source,nextflow,linenums]
----
include {sayHello} from './some/module' addParams(foo: 'Ciao')

workflow {
    sayHello()
}
----

The above snippet should prints:

[source,bash,linenums]
----
Ciao world!
----

Finally the include option `params` allows the specification of one or more parameters without inheriting any value from the external environment.

[discrete]
=== Exercise

Try to run the above code. Replacing `./some/module` with the file name to a process called `sayHello()`, which expects `foo` and `bar` parameters. Remember to use ./ for current directory.

.Answer:
[%collapsible]
====
1. First save the following to `./modules/my_modules.nf`:
+
[source,nextflow,linenums]
----
params.foo = 'Hello'
params.bar = 'world!'

def sayHello() {
    println "$params.foo $params.bar"
}
----
+
2. Then run `nextflow run myscript.nf`:
+
Where `myscript.nf` is the following:
[source,nextflow,linenums]
----
nextflow.enable.dsl=2

params.foo = 'Hola'
params.bar = 'Mundo'

include {sayHello} from './modules/my_modules.nf'

workflow {
    sayHello()
}
----
====

== Other useful DSL2 changes

Some of the syntax has changed between DSL1 and DSL2. 

These are a few of the key changes:

- Process inputs and outputs of type `set` have to be replaced with `tuple`.

- Process output option mode `flatten` is not available anymore. Replace it using the `flatten` operator on the corresponding output channel.

- Anonymous and unwrapped includes are not supported anymore. Replace it with a explicit module inclusion. For example:

[source,nextflow,linenums]
----
include './some/library'
include bar from './other/library'

workflow {
  foo()
  bar()
}
----

Should be replaced with:

[source,nextflow,linenums]
----
include { foo } from './some/library'
include { bar } from './other/library'

workflow {
  foo()
  bar()
}
----

- The use of unqualified value (`val`) and `file` elements into input tuples is not allowed anymore. Replace them with a corresponding `val` or `path` qualifiers:

[source,nextflow,linenums]
----
process foo {
input:
  tuple X, 'some-file.bam'
 script:
   '''
   your_command
   '''
}
----

Use:

[source,nextflow,linenums]
----
process foo {
input:
  tuple val(X), path('some-file.bam')
 script:
   '''
   your_command --in $X some-file.bam
   '''
}
----

For more information, check out the full details of DSL2 changes at this https://www.nextflow.io/docs/latest/dsl2.html[link]


