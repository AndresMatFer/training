= DSL2: simpler syntax, modules and beyond

== Basic concepts

DSL2 is our new syntax to improve readability and allow the use of modules, as well as a few extra improvements. 

Despite this and to allow backward compatibility to exisiting pipelines, DSL1 is still a valid way of writing pipelines (and indeed many online pipelines are written this way) and therefore the dsl2 update has to be defined with the following directive at the beginning of your workflow script: 

----
nextflow.enable.dsl=2
----

DSL2 core features include:

* Improved readability of pipelines 
* Splitting of processes into modules that are portable between pipelines/workflows


=== Process

== Process definition

The new DSL separates the definition of a process from its invocation. The process definition follows the usual syntax as described in the process documentation. The only difference is that the `from` and `into` channel declaration has to be omitted.

Then a process can be invoked as a function in the `workflow` scope, passing the expected input channels as parameters as it if were a custom function. For example :


----
nextflow.enable.dsl=2

process foo {
    output:
      path 'foo.txt'
    script:
      """
      echo first_command > foo.txt
      """
}

workflow {
  foo()
}
----

At the first line we enable dsl2, then we define a process called 'foo', which puts into the output channel (path: foo.txt) the output of the script. This is then executed in the workflow directive where the individual process is called.

Warning: A process component can be invoked only once in the same workflow context.

Next, we can add additional processes to this script and add another call from the workflow directive, thereby separating the processes into 'submodules'. This separation makes complex pipelines easier to follow and reuse.

----
nextflow.enable.dsl=2

process foo {
    output:
      path 'foo.txt'
    script:
      """
      echo first_command > foo.txt
      """
}

process bar {
    input:
      path x
    output:
      path 'bar.txt'
    script:
      """
      echo second command > bar.txt
      head -n 1 $x >> bar.txt
      """
}

workflow {
  foo()
  data = channel.fromPath('data/ggal/gut_1.fq')
  bar(data)
}
----

In this example, we have added the second process 'bar', which again is called within the latter workflow directive, where its input comes from a specified Path. 


== Process composition
Processes having matching input-output declaration can be composed so that the output of the first process is passed as input to the following process. Taking in consideration the previous process definition, it’s possible to write the following:


----
workflow {
    bar(foo())
}
----

== Process outputs
A process output can also be accessed using the `out` attribute for the respective process object. For example:


----
workflow {
    foo()
    bar(foo.out)
    bar.out.view()
}
----

When a process defines two or more output channels, each of them can be accessed using the array element operator e.g. `out[0]`, `out[1]`, etc. or using named outputs (see below).

== Process named output
The process output definition allows the use of the `emit` option to define a name identifier that can be used to reference the channel in the external scope. For example:


----
process foo {
  output:
    path '*.bam', emit: samples_bam

  '''
  your_command --here
  '''
}

workflow {
    foo()
    foo.out.samples_bam.view()
}
----

== Process named stdout
The process can name stdout using the `emit` option:


----
process sayHello {
    input:
        val cheers
    output:
        stdout emit: verbiage
    script:
    """
    echo -n $cheers
    """
}

workflow {
    things = channel.of('Hello world!', 'Yo, dude!', 'Duck!')
    sayHello(things)
    sayHello.out.verbiage.view()
}
----

=== Workflow

== Workflow definition
The `workflow` keyword allows the definition of sub-workflow components that enclose the invocation of one or more processes and operators:


----
workflow my_pipeline {
    foo()
    bar( foo.out.collect() )
}
----

For example, the above snippet defines a workflow component, named `my_pipeline`, that can be invoked from another workflow component definition as any other function or process i.e. `my_pipeline()`.

== Workflow parameters
A workflow component can access any variable and parameter defined in the outer scope:

----
params.data = '/some/data/file'

workflow my_pipeline {
    if( params.data )
        bar(params.data)
    else
        bar(foo())
}
----

== Workflow inputs
A workflow component can declare one or more input channels using the take keyword. For example:

----
workflow my_pipeline {
    take: data
    main:
    foo(data)
    bar(foo.out)
}
----
Warning: When the take keyword is used, the beginning of the workflow body needs to be identified with the main keyword.

Then, the input can be specified as an argument in the workflow invocation statement:

----
workflow {
    my_pipeline( channel.from('/some/data') )
}
----
NOTE: Workflow inputs are by definition channel data structures. If a basic data type is provided instead, ie. number, string, list, etc. it’s implicitly converted to a channel value (ie. non-consumable).

== Workflow outputs
A workflow component can declare one or more out channels using the emit keyword. For example:

----
workflow my_pipeline {
    main:
      foo(data)
      bar(foo.out)
    emit:
      bar.out
}
----

Then, the result of the my_pipeline execution can be accessed using the out property ie. my_pipeline.out. When there are multiple output channels declared, use the array bracket notation to access each output component as described for the Process outputs definition.

Alternatively, the output channel can be accessed using the identifier name which it’s assigned to in the emit declaration:

----
workflow my_pipeline {
   main:
     foo(data)
     bar(foo.out)
   emit:
     my_data = bar.out
}
----
Then, the result of the above snippet can accessed using my_pipeline.out.my_data.

== Implicit workflow
A workflow definition which does not declare any name is assumed to be the main workflow and it’s implicitly executed. Therefore it’s the entry point of the workflow application.

NOTE: Implicit workflow definition is ignored when a script is included as module. This allows the writing of a workflow script that can be used either as a library module and as application script.

TIP: An alternative workflow entry can be specified using the -entry command line option.

== Workflow composition
Workflows defined in your script or imported by a module inclusion can be invoked and composed as any other process in your application.

----
workflow flow1 {
    take: data
    main:
        foo(data)
        bar(foo.out)
    emit:
        bar.out
}

workflow flow2 {
    take: data
    main:
        foo(data)
        baz(foo.out)
    emit:
        baz.out
}

workflow {
    take: data
    main:
      flow1(data)
      flow2(flow1.out)
}
----

NOTE: Nested workflow execution determines an implicit scope. Therefore the same process can be invoked in two different workflow scopes, like for example foo in the above snippet that is used either in flow1 and flow2. The workflow execution path along with the process names defines the process fully qualified name that is used to distinguish the two different process invocations i.e. flow1:foo and flow2:foo in the above example.

TIP : The process fully qualified name can be used as a valid process selector in the nextflow.config file and it has priority over the process simple name.

=== Modules
The new DSL allows the definition module scripts that can be included and shared across workflow applications.

A module can contain the definition of a function, process and workflow definitions as described in the above sections.

== Modules include
A component defined in a module script can be imported into another Nextflow script using the include keyword.

For example:

----
include { foo } from './some/module'

workflow {
    data = channel.fromPath('/some/data/*.txt')
    foo(data)
}
----

The above snippets includes a process with name foo defined in the module script in the main execution context, as such it can be invoked in the workflow scope.

Nextflow implicitly looks for the script file ./some/module.nf resolving the path against the including script location.

NOTE: Relative paths must begin with the ./ prefix.

== Multiple inclusions
A Nextflow script allows the inclusion of any number of modules. When multiple components need to be included from the some module script, the component names can be specified in the same inclusion using the curly brackets notation as shown below:

----
include { foo; bar } from './some/module'

workflow {
    data = channel.fromPath('/some/data/*.txt')
    foo(data)
    bar(data)
}
----

== Module aliases
When including a module component it’s possible to specify a name alias. This allows the inclusion and the invocation of the same component multiple times in your script using different names. For example:

----
include { foo } from './some/module'
include { foo as bar } from './other/module'

workflow {
    foo(some_data)
    bar(other_data)
}
----
The same is possible when including multiple components from the same module script as shown below:

----
include { foo; foo as bar } from './some/module'

workflow {
    foo(some_data)
    bar(other_data)
}
----

== Module parameters
A module script can define one or more parameters using the same syntax of a Nextflow workflow script:

----
params.foo = 'Hello'
params.bar = 'world!'

def sayHello() {
    println "$params.foo $params.bar"
}
----

Then, parameters are inherited from the including context. For example:

----
params.foo = 'Hola'
params.bar = 'Mundo'

include {sayHello} from './some/module'

workflow {
    sayHello()
}
----
The above snippet prints:
----
Hola Mundo
----

NOTE: The module inherits the parameters define before the include statement, therefore any further parameter set later is ignored.

TIP: Define all pipeline parameters at the beginning of the script before any include declaration.

The option addParams can be used to extend the module parameters without affecting the external scope. For example:

----
include {sayHello} from './some/module' addParams(foo: 'Ciao')

workflow {
    sayHello()
}
----

The above snippet prints:

----
Ciao world!
----

Finally the include option params allows the specification of one or more parameters without inheriting any value from the external environment.

=== DSL2 migration notes

DSL2 final version is activated using the declaration nextflow.enable.dsl=2 in place of nextflow.preview.dsl=2.

Process inputs of type set have to be replaced with tuple.

Process outputs of type set have to be replaced with tuple.

Process output option mode flatten is not available anymore. Replace it using the flatten operator on the corresponding output channel.

Anonymous and unwrapped includes are not supported anymore. Replace it with a explicit module inclusion. For example: